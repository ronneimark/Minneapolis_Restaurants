{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:25.921386Z",
     "start_time": "2020-03-09T06:06:24.906076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported...\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from config import yelp_key\n",
    "from config import google_key\n",
    "from config import foursquare_id\n",
    "from config import foursquare_secret\n",
    "import time\n",
    "import datetime\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "from config import password\n",
    "from config import username\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import PrimaryKeyConstraint\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime\n",
    "from sqlalchemy.schema import Sequence\n",
    "\n",
    "print(f'Dependencies imported...',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspections Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:38.394405Z",
     "start_time": "2020-03-09T06:06:25.923369Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Food_Inspections/FeatureServer/0/query?'\n",
    "params = \"where=FacilityCategory%20%3D%20%27RESTAURANT%27\"\n",
    "outfields = \"&outFields=BusinessName,HealthFacilityIDNumber,FullAddress,InspectionType,DateOfInspection,InspectionIDNumber,InspectionScore,Latitude,Longitude,FoodCodeText,ViolationPoints,InspectionResult,FoodCodeItem,InspectorComments,ViolationStatus,ViolationPriority&returnGeometry=false&outSR=4326\"\n",
    "json = '&f=json'\n",
    "\n",
    "full_url = url+params+outfields+json\n",
    "\n",
    "response = requests.get(full_url)\n",
    "\n",
    "data=response.json()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:38.575440Z",
     "start_time": "2020-03-09T06:06:38.397877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspection_data_list with needed data has been built.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "inspection_data_list = []\n",
    "\n",
    "for records in data:\n",
    "    item = records['attributes']\n",
    "    item['DateOfInspection']=time.strftime('%Y/%m/%d',time.gmtime(records['attributes']['DateOfInspection']/1000))\n",
    "    inspection_data_list.append(item)\n",
    "    \n",
    "print('inspection_data_list with needed data has been built.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:38.895350Z",
     "start_time": "2020-03-09T06:06:38.577424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspection Detail DataFrame now stored in memory as \"inspection_detail\"\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "inspections_df_base = pd.DataFrame(inspection_data_list)\n",
    "\n",
    "inspections_df_1 = inspections_df_base[['InspectionIDNumber','DateOfInspection','BusinessName','FullAddress','InspectionType','InspectionScore','Latitude','Longitude']]\n",
    "inspections_df_1 = inspections_df_1.drop_duplicates(subset='InspectionIDNumber', keep='first')\n",
    "inspections_df_1 = inspections_df_1.sort_values(by=['BusinessName','DateOfInspection'])\n",
    "inspections_df_1 = inspections_df_1.rename(columns={'BusinessName':'inspect_name','FullAddress':'address','Latitude':'latitude','Longitude':'longitude','InspectionIDNumber':'inspectionidnumber','DateOfInspection':'dateofinspection','InspectionScore':'inspectionscore','InspectionType':'inspectiontype'})\n",
    "\n",
    "inspections_detail = inspections_df_base[['DateOfInspection','InspectionIDNumber','BusinessName','FullAddress','InspectionType','InspectionScore','InspectionResult','FoodCodeItem','FoodCodeText','InspectorComments','ViolationPriority','ViolationStatus','ViolationPoints']]\n",
    "inspections_detail = inspections_detail.sort_values(by=['BusinessName','DateOfInspection'])\n",
    "inspections_detail = inspections_detail.rename(columns={'InspectionIDNumber':'inspectionidnumber','DateOfInspection':'dateofinspection','BusinessName':'businessname','FullAddress':'fulladdress','InspectionType':'inspectiontype','InspectionScore':'inspectionscore','InspectionResult':'inspectionresult','FoodCodeItem':'foodcodeitem','FoodCodeText':'foodcodetext','InspectorComments':'inspectorcomments','ViolationPriority':'violationpriority','ViolationStatus':'violationstatus','ViolationPoints':'violationpoints'})\n",
    "\n",
    "print('Inspection Detail DataFrame now stored in memory as \"inspection_detail\"',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:39.428057Z",
     "start_time": "2020-03-09T06:06:38.897831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspections Dictionaries list now stored in memory as \"grand_master_list\"\n",
      "There are 6175 inspections for 1554 facilities.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "grand_master_data=inspections_df_1.groupby(['inspect_name','address','latitude','longitude'],sort=False,as_index=False).aggregate(lambda x: list(x))\n",
    "grand_master_list = grand_master_data.to_dict('records')\n",
    "\n",
    "for item in grand_master_list:\n",
    "    currentDT=datetime.datetime.now()\n",
    "    item.update(updated = currentDT.strftime(\"%a, %b %d, %Y at %I:%M %p\"))\n",
    "\n",
    "print('Inspections Dictionaries list now stored in memory as \"grand_master_list\"', flush=True)\n",
    "print(f'There are {len(inspections_df_1)} inspections for {len(grand_master_list)} facilities.',flush=True)\n",
    "\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:06:39.438495Z",
     "start_time": "2020-03-09T06:06:39.430556Z"
    }
   },
   "outputs": [],
   "source": [
    "Bad_Categories = [\n",
    " 'Adult Entertainment',\n",
    " 'Airport Shuttles',\n",
    " 'Apartments',\n",
    " 'Appliances & Repair',\n",
    " 'Arcades',\n",
    " 'Art Galleries',\n",
    " 'Art Museums',\n",
    " 'Art Schools',\n",
    " 'Arts & Crafts',\n",
    " 'Assisted Living Facilities',\n",
    " 'Auto Detailing',\n",
    " 'Auto Insurance',\n",
    " 'Auto Repair',\n",
    " 'Axe Throwing',\n",
    " 'Banks & Credit Unions',\n",
    " 'Barbers',\n",
    " 'Beverage Store',\n",
    " 'Bike Repair/Maintenance',\n",
    " 'Bikes',\n",
    " 'Blood & Plasma Donation Centers',\n",
    " 'Body Shops',\n",
    " 'Bookstores',\n",
    " 'Bowling',\n",
    " 'Building Supplies',\n",
    " 'Cabinetry',\n",
    " 'Candy Stores',\n",
    " 'Car Wash',\n",
    " 'Caterers',\n",
    " 'Cardiologists',\n",
    " 'Chiropractors',\n",
    " 'Churches',\n",
    " 'Colleges & Universities',\n",
    " 'Comedy Clubs',\n",
    " 'Community Centers',\n",
    " 'Community Service/Non-Profit',\n",
    " 'Convenience Stores',\n",
    " 'Conveyor Belt Sushi',\n",
    " 'Cooking Classes',\n",
    " 'Cooking Schools',\n",
    " 'Cosmetic Dentists',\n",
    " 'Cosmetics & Beauty Supply',\n",
    " 'CSA',\n",
    " 'Cultural Center',\n",
    " 'Dance Clubs',\n",
    " 'Department Stores',\n",
    " 'Discount Store',\n",
    " 'Drugstores',\n",
    " 'Electronics',\n",
    " 'Employment Agencies',\n",
    " 'Endodontists',\n",
    " 'Financial Advising',\n",
    " 'Florists',\n",
    " 'Furniture Stores',\n",
    " 'Gas Stations',\n",
    " 'General Dentistry',\n",
    " 'Gift Shops',\n",
    " 'Golf',\n",
    " 'Grocery',\n",
    " 'Guest Houses',\n",
    " 'Gyms',\n",
    " 'Hair Extensions',\n",
    " 'Hair Salons',\n",
    " 'Hardware Stores',\n",
    " 'Health Markets',\n",
    " 'Historical Tours',\n",
    " 'Home & Rental Insurance',\n",
    " 'Hospitals',\n",
    " 'Hotels',\n",
    " 'Imported Food',\n",
    " 'International Grocery',\n",
    " 'Interior Design',\n",
    " 'Investing',\n",
    " 'IT Services & Computer Repair',\n",
    " 'Jazz & Blues',\n",
    " 'Jewelry',\n",
    " 'Karaoke',\n",
    " 'Kitchen Supplies',\n",
    " 'Knife Sharpening',\n",
    " 'Landmarks & Historical Buildings',\n",
    " 'Landscaping',\n",
    " 'Laser Eye Surgery/Lasik',\n",
    " 'Life Insurance',\n",
    " 'Limos',\n",
    " 'Massage Therapy',\n",
    " 'Medical Centers',\n",
    " 'Medical Spas',\n",
    " \"Men's Clothing\",\n",
    " 'Mobile Phone Accessories',\n",
    " 'Mobile Phone Repair',\n",
    " 'Mobile Phones',\n",
    " 'Mortgage Brokers',\n",
    " 'Museums',\n",
    " 'Music & DVDs',\n",
    " 'Music Venues',\n",
    " 'Nail Salons',\n",
    " 'Nurseries & Gardening',\n",
    " 'Ophthalmologists',\n",
    " 'Organic Stores',\n",
    " 'Orthopedists',\n",
    " 'Outlet Stores',\n",
    " 'Parking',\n",
    " 'Parks',\n",
    " 'Party & Event Planning',\n",
    " 'Party Bus Rentals',\n",
    " 'Performing Arts',\n",
    " 'Personal Care Services',\n",
    " 'Pharmacy',\n",
    " 'Print Media',\n",
    " 'Professional Sports Teams',\n",
    " 'Psychiatrists',\n",
    " 'Public Transportation',\n",
    " 'Radio Stations',\n",
    " 'Religious Organizations',\n",
    " 'Retirement Homes',\n",
    " 'Shopping Centers',\n",
    " 'Skilled Nursing',\n",
    " 'Social Clubs',\n",
    " 'Spray Tanning',\n",
    " 'Strip Clubs',\n",
    " 'Tattoo',\n",
    " 'Taxis',\n",
    " 'Tires',\n",
    " 'Trainers',\n",
    " 'Venues & Event Spaces',\n",
    " 'Videos & Video Game Rental',\n",
    " 'Vinyl Records',\n",
    " 'Vitamins & Supplements',\n",
    " 'Waxing',\n",
    " 'Wedding Planning',\n",
    " 'Wheel & Rim Repair',\n",
    " 'Wholesale Stores',\n",
    " 'Wigs',\n",
    " 'Wine Tours',\n",
    " 'Women\\'s Clothing',\n",
    " 'Yoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:21:22.416895Z",
     "start_time": "2020-03-09T06:09:23.841154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download restaurants as the search parameter.\n",
    "\n",
    "i=0\n",
    "\n",
    "headers = {'Authorization': 'Bearer %s' % yelp_key}\n",
    "\n",
    "url='https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "print('Downloading Yelp Data for each restaurant...',flush=True)\n",
    "\n",
    "no_yelp=[]\n",
    "\n",
    "for item in grand_master_list:\n",
    "    \n",
    "    if item['inspect_name'].split()[0] != \"THE\":\n",
    "        params = {\n",
    "            'term':item['inspect_name'].split()[0],\n",
    "    #         'term':item['inspect_name'],\n",
    "            'latitude':item['latitude'],\n",
    "            'longitude':item['longitude'],\n",
    "            'radius':200,\n",
    "            \"sort_by\":\"distance\"\n",
    "            }\n",
    "    else:\n",
    "    \n",
    "        params = {\n",
    "            'term':item['inspect_name'].split()[1],\n",
    "    #         'term':item['inspect_name'],\n",
    "            'latitude':item['latitude'],\n",
    "            'longitude':item['longitude'],\n",
    "            'radius':200,\n",
    "            \"sort_by\":\"distance\"\n",
    "            }\n",
    "        \n",
    "    response=requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        yelp= response.json()['businesses']\n",
    "        if len(yelp)>0:\n",
    "            if 'categories' in yelp[0]:\n",
    "                categories=[]\n",
    "                for cat in yelp[0]['categories']:\n",
    "                    category = cat['title']\n",
    "                    if category not in Bad_Categories:\n",
    "                        categories.append(category)\n",
    "                    if len(categories) != 0:\n",
    "                        item.update(yelp_categories=categories)\n",
    "                        if 'name' in yelp[0]: \n",
    "                            item.update(yelp_name = yelp[0]['name'])\n",
    "                        if 'id' in yelp[0]:\n",
    "                            item.update(yelp_id= yelp[0]['id'])\n",
    "                        if 'price' in yelp[0]:\n",
    "                            item.update(yelp_price=yelp[0]['price'])\n",
    "                        if 'url'in yelp[0]:\n",
    "                            item.update(yelp_url=yelp[0]['url'])\n",
    "                        if 'transactions' in yelp[0]:\n",
    "                            item.update(yelp_transactions=yelp[0]['transactions'])\n",
    "                        if 'display_phone' in yelp[0]:\n",
    "                            item.update(yelp_phone=yelp[0]['display_phone'])\n",
    "                        if len('display_address') in yelp[0]['location'] > 1:\n",
    "                            item.update(address=yelp[0]['location']['display_address'][0]+\", \"+yelp[0]['location']['display_address'][1])\n",
    "                        if 'rating' in yelp[0]:\n",
    "                            item.update(yelp_rating=yelp[0]['rating'])\n",
    "                        if 'review_count' in yelp[0]:\n",
    "                            item.update(yelp_reviews=yelp[0]['review_count'])\n",
    "                        if 'latitude' in yelp[0]:\n",
    "                            item.update(latitude=yelp[0]['latitude'])\n",
    "                        if 'longitude' in yelp[0]:\n",
    "                            item.update(longitude=yelp[0]['longitude'])\n",
    "                        currentDT=datetime.datetime.now()\n",
    "                        item.update(updated = currentDT.strftime(\"%a, %b %d, %Y at %I:%M %p\"))\n",
    "          \n",
    "    elif response.status_code == 400:\n",
    "        print('400 Bad Request')\n",
    "        break\n",
    "        \n",
    "    print(\"Restaurants Remaining: {:4}\".format(len(grand_master_list)-i), end=\"\\r\",flush=True)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "for item in grand_master_list:\n",
    "    if 'yelp_rating' not in item:\n",
    "        no_yelp.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "\n",
    "for item in grand_master_list:\n",
    "    if 'yelp_reviews' not in item:\n",
    "        no_yelp.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "        \n",
    "for item in grand_master_list:\n",
    "    if 'yelp_categories' not in item:\n",
    "        no_yelp.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "        \n",
    "for item in grand_master_list:\n",
    "    if 'yelp_name' not in item:\n",
    "        no_yelp.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "\n",
    "no_yelp_df=pd.DataFrame(no_yelp)\n",
    "no_yelp_df.to_csv('DataFiles/NoYelp.csv')\n",
    "\n",
    "print('---------------',flush=True)\n",
    "print(f'Yelp data downloaded and added to grand_master_list...',flush=True)\n",
    "print(f'{len(no_yelp)} records from the inspections list were not found in Yelp search (name, categories, rating, and reviews).',flush=True)  \n",
    "print('Those records have been removed from grand_master_list and saved to a csv called \"NoYelp.csv\".',flush=True)\n",
    "print(f'There are now {len(grand_master_list)} restaurants remaining in grand_master_list.', flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:19:26.809016Z",
     "start_time": "2020-03-09T15:19:26.799591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acai Bowls': 2,\n",
       " 'African': 17,\n",
       " 'American (New)': 71,\n",
       " 'American (Traditional)': 96,\n",
       " 'Argentine': 1,\n",
       " 'Asian Fusion': 20,\n",
       " 'Bagels': 9,\n",
       " 'Bakeries': 46,\n",
       " 'Barbeque': 12,\n",
       " 'Bars': 65,\n",
       " 'Beer Bar': 13,\n",
       " 'Beer, Wine & Spirits': 8,\n",
       " 'Brasseries': 1,\n",
       " 'Brazilian': 1,\n",
       " 'Breakfast & Brunch': 124,\n",
       " 'Breweries': 4,\n",
       " 'Brewpubs': 2,\n",
       " 'British': 6,\n",
       " 'Bubble Tea': 10,\n",
       " 'Buffets': 6,\n",
       " 'Burgers': 65,\n",
       " 'Butcher': 5,\n",
       " 'Cafes': 46,\n",
       " 'Cajun/Creole': 3,\n",
       " 'Cambodian': 2,\n",
       " 'Cantonese': 2,\n",
       " 'Caribbean': 4,\n",
       " 'Cheese Shops': 3,\n",
       " 'Cheesesteaks': 1,\n",
       " 'Chicken Shop': 3,\n",
       " 'Chicken Wings': 28,\n",
       " 'Chinese': 49,\n",
       " 'Chocolatiers & Shops': 1,\n",
       " 'Cocktail Bars': 24,\n",
       " 'Coffee & Tea': 164,\n",
       " 'Coffee Roasteries': 7,\n",
       " 'Colombian': 1,\n",
       " 'Comfort Food': 4,\n",
       " 'Creperies': 4,\n",
       " 'Cuban': 3,\n",
       " 'Cupcakes': 2,\n",
       " 'Custom Cakes': 4,\n",
       " 'Delis': 31,\n",
       " 'Desserts': 23,\n",
       " 'Dim Sum': 1,\n",
       " 'Diners': 20,\n",
       " 'Dive Bars': 23,\n",
       " 'Donuts': 10,\n",
       " 'Ethiopian': 6,\n",
       " 'Falafel': 6,\n",
       " 'Farmers Market': 2,\n",
       " 'Fast Food': 64,\n",
       " 'Filipino': 1,\n",
       " 'Fish & Chips': 4,\n",
       " 'Fondue': 1,\n",
       " 'Food Court': 1,\n",
       " 'Food Delivery Services': 1,\n",
       " 'Food Stands': 1,\n",
       " 'Food Trucks': 10,\n",
       " 'French': 3,\n",
       " 'Fruits & Veggies': 3,\n",
       " 'Gastropubs': 5,\n",
       " 'Gay Bars': 5,\n",
       " 'Gelato': 1,\n",
       " 'German': 4,\n",
       " 'Gluten-Free': 10,\n",
       " 'Greek': 9,\n",
       " 'Halal': 2,\n",
       " 'Hawaiian': 1,\n",
       " 'Himalayan/Nepalese': 4,\n",
       " 'Hookah Bars': 2,\n",
       " 'Hot Dogs': 8,\n",
       " 'Hot Pot': 2,\n",
       " 'Ice Cream & Frozen Yogurt': 17,\n",
       " 'Indian': 12,\n",
       " 'Irish': 3,\n",
       " 'Irish Pub': 6,\n",
       " 'Italian': 36,\n",
       " 'Japanese': 20,\n",
       " 'Juice Bars & Smoothies': 22,\n",
       " 'Kombucha': 2,\n",
       " 'Korean': 7,\n",
       " 'Latin American': 16,\n",
       " 'Lebanese': 2,\n",
       " 'Lounges': 11,\n",
       " 'Macarons': 1,\n",
       " 'Malaysian': 3,\n",
       " 'Meat Shops': 10,\n",
       " 'Mediterranean': 18,\n",
       " 'Mexican': 64,\n",
       " 'Middle Eastern': 14,\n",
       " 'Modern European': 2,\n",
       " 'Moroccan': 2,\n",
       " 'New Mexican Cuisine': 1,\n",
       " 'Noodles': 7,\n",
       " 'Pan Asian': 4,\n",
       " 'Pasta Shops': 2,\n",
       " 'Persian/Iranian': 2,\n",
       " 'Piano Bars': 1,\n",
       " 'Pizza': 70,\n",
       " 'Poke': 4,\n",
       " 'Polish': 1,\n",
       " 'Popcorn Shops': 1,\n",
       " 'Pubs': 28,\n",
       " 'Ramen': 8,\n",
       " 'Russian': 1,\n",
       " 'Salad': 47,\n",
       " 'Salvadoran': 2,\n",
       " 'Sandwiches': 113,\n",
       " 'Scottish': 1,\n",
       " 'Seafood': 30,\n",
       " 'Seafood Markets': 1,\n",
       " 'Smokehouse': 1,\n",
       " 'Somali': 8,\n",
       " 'Soul Food': 5,\n",
       " 'Soup': 13,\n",
       " 'Southern': 3,\n",
       " 'Spanish': 1,\n",
       " 'Speakeasies': 1,\n",
       " 'Specialty Food': 2,\n",
       " 'Sports Bars': 27,\n",
       " 'Steakhouses': 16,\n",
       " 'Street Vendors': 2,\n",
       " 'Sushi Bars': 29,\n",
       " 'Szechuan': 4,\n",
       " 'Tacos': 11,\n",
       " 'Taiwanese': 1,\n",
       " 'Tapas/Small Plates': 5,\n",
       " 'Tea Rooms': 1,\n",
       " 'Tex-Mex': 3,\n",
       " 'Thai': 16,\n",
       " 'Trainers': 1,\n",
       " 'Turkish': 1,\n",
       " 'Vegan': 11,\n",
       " 'Vegetarian': 5,\n",
       " 'Vietnamese': 25,\n",
       " 'Waffles': 3,\n",
       " 'Wine Bars': 21,\n",
       " 'Wraps': 2}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code snippet iterates through the categories in each record and creates a list of unique category names.\n",
    "\n",
    "category_dict={}\n",
    "for items in grand_master_list:\n",
    "    if 'yelp_categories' in items:\n",
    "        for category in items['yelp_categories']:\n",
    "        \n",
    "            if category not in category_dict.keys():\n",
    "                category_dict.update({category:1})\n",
    "            else:\n",
    "                category_dict[category]+=1\n",
    "\n",
    "sorted_categories=sorted(category_dict.keys(), key=lambda x:x.lower())\n",
    "\n",
    "sorted_cat_dict= {}\n",
    "for key in sorted_categories:\n",
    "    sorted_cat_dict.update({key: category_dict[key]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:21:22.541396Z",
     "start_time": "2020-03-09T06:21:22.436736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 restaurants downloaded from Yelp had less than 25% similarity in name when compared to the name in the inspections DB.\n",
      "Assuming these are different establishments, they have been removed from grand_master_list.\n",
      "They have been saved to a csv called \"YelpLackSimilarity.csv\".\n",
      "There are now 1554 restaurants left in grand_master_data.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "lack_similarity = []\n",
    "\n",
    "for items in grand_master_list:\n",
    "    if 'yelp_name' in items:\n",
    "        s = SequenceMatcher(None, items['inspect_name'], items['yelp_name'].upper())\n",
    "        s_ratio = s.ratio()\n",
    "        if s_ratio <.25:\n",
    "            dict={}\n",
    "            dict[\"INSPECTION\"] = items['inspect_name'].lower()\n",
    "            dict[\"YELP\"] = items['yelp_name'].lower()\n",
    "            dict[\"RATIO\"] = str(s.ratio())\n",
    "            lack_similarity.append(dict)\n",
    "            grand_master_list.remove(items)\n",
    "            \n",
    "yelp_lack_similarity_df=pd.DataFrame(lack_similarity)\n",
    "yelp_lack_similarity_df.to_csv('DataFiles/YelpLackSimilarity.csv')\n",
    "\n",
    "print(f'{len(lack_similarity)} restaurants downloaded from Yelp had less than 25% similarity in name when compared to the name in the inspections DB.', flush=True)\n",
    "print('Assuming these are different establishments, they have been removed from grand_master_list.', flush=True)\n",
    "print('They have been saved to a csv called \"YelpLackSimilarity.csv\".', flush=True)\n",
    "print(f'There are now {len(grand_master_list)} restaurants left in grand_master_list.', flush=True)\n",
    "print('---------------',flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:32:08.088150Z",
     "start_time": "2020-03-09T06:21:22.545857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending Google Data to grand_master_list...   This will take some time, as we match each record...\n",
      "Google data downloaded and added to grand_master_list...\n",
      "8 records from the inspections list were not found in Google search (rating and reviews).\n",
      "Those records have been removed from grand_master_list and saved to a csv called \"NoGoogle.csv\".\n",
      "There are now 1049 restaurants remaining in grand_master_list.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print('Appending Google Data to grand_master_list...   This will take some time, as we match each record...',flush=True)\n",
    "\n",
    "url = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?'\n",
    "\n",
    "i=0\n",
    "\n",
    "no_google=[]\n",
    "\n",
    "for item in grand_master_list:\n",
    "    \n",
    "    params = {\n",
    "        'key':google_key,\n",
    "        'input':item['inspect_name'],\n",
    "        'inputtype':'textquery',\n",
    "        'locationbias': 'point:' + str(item['latitude']) + \", \" + str(item['longitude']),\n",
    "        'radius': 100,\n",
    "        'fields':'place_id,formatted_address,name,rating,user_ratings_total,price_level'\n",
    "        }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    json=response.json()\n",
    "    \n",
    "    if len(response.json()['candidates'])>0:\n",
    "        if 'name' in json['candidates'][0]: \n",
    "            item.update(google_name =json['candidates'][0]['name'])\n",
    "        if 'formatted_address' in json['candidates'][0]: \n",
    "            item.update(address =json['candidates'][0]['formatted_address'])\n",
    "        if 'place_id' in json['candidates'][0]:\n",
    "            item.update(google_id=json['candidates'][0]['place_id'])\n",
    "        if 'rating' in json['candidates'][0]:\n",
    "            item.update(google_rating=json['candidates'][0]['rating'])\n",
    "        if 'user_ratings_total' in json['candidates'][0]:\n",
    "            item.update(google_reviews = json['candidates'][0]['user_ratings_total'])\n",
    "        if 'price_level' in json['candidates'][0]:\n",
    "            item.update(google_price =json['candidates'][0]['price_level'])\n",
    "        currentDT=datetime.datetime.now()\n",
    "        item.update(updated = currentDT.strftime(\"%a, %b %d, %Y at %I:%M %p\"))\n",
    "    \n",
    "    print(\"Restaurants Remaining: {:4}\".format(len(grand_master_list)-i), end=\"\\r\",flush=True)\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "for item in grand_master_list:\n",
    "    if 'google_rating' not in item:\n",
    "        no_google.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "    \n",
    "for item in grand_master_list:\n",
    "    if 'google_reviews' not in item:\n",
    "        no_google.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "        \n",
    "for item in grand_master_list:\n",
    "    if 'google_name' not in item:\n",
    "        no_google.append(item)\n",
    "        grand_master_list.remove(item)\n",
    "        \n",
    "no_google_df =  pd.DataFrame(no_google)\n",
    "no_google_df.to_csv('DataFiles/NoGoogle.csv')\n",
    "\n",
    "print('---------------',flush=True)\n",
    "print(f'Google data downloaded and added to grand_master_list...',flush=True)\n",
    "print(f'{len(no_google)} records from the inspections list were not found in Google search (rating and reviews).',flush=True)  \n",
    "print('Those records have been removed from grand_master_list and saved to a csv called \"NoGoogle.csv\".',flush=True)\n",
    "print(f'There are now {len(grand_master_list)} restaurants remaining in grand_master_list.', flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:32:42.853398Z",
     "start_time": "2020-03-09T06:32:42.766598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 restaurants downloaded from Google had less than 25% similarity in name when compared to the name in the inspections DB.\n",
      "Assuming these are different establishments, they have been removed from grand_master_list.\n",
      "They have been saved to a csv called \"GoogleLackSimilarity.csv\".\n",
      "There are now 1045 restaurants left in grand_master_list.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "google_lack_similarity = []\n",
    "\n",
    "for items in grand_master_list:\n",
    "    if 'google_name' in items:\n",
    "        s = SequenceMatcher(None, items['inspect_name'], items['google_name'].upper())\n",
    "        s_ratio = s.ratio()\n",
    "        if s_ratio <.25:\n",
    "            dict={}\n",
    "            dict[\"INSPECTION\"] = items['inspect_name'].lower()\n",
    "            dict[\"GOOGLE\"] = items['google_name'].lower()\n",
    "            dict[\"RATIO\"] = str(s.ratio())\n",
    "            lack_similarity.append(dict)\n",
    "            grand_master_list.remove(items)\n",
    "            \n",
    "google_lack_similarity_df=pd.DataFrame(lack_similarity)\n",
    "google_lack_similarity_df.to_csv('DataFiles/GoogleLackSimilarity.csv')\n",
    "\n",
    "print(f'{len(google_lack_similarity)} restaurants downloaded from Google had less than 25% similarity in name when compared to the name in the inspections DB.', flush=True)\n",
    "print('Assuming these are different establishments, they have been removed from grand_master_list.', flush=True)\n",
    "print('They have been saved to a csv called \"GoogleLackSimilarity.csv\".', flush=True)\n",
    "print(f'There are now {len(grand_master_list)} restaurants left in grand_master_list.', flush=True)\n",
    "print('---------------',flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:51:22.371285Z",
     "start_time": "2020-03-09T06:51:22.280033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_rating and total_reviews fields created by combining Yelp and Google Ratings and Reviews.\n",
      "grand_master_list is now complete, has been saved as csv named \"MasterList.csv\".\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Create a new Aggregate Score and Review Count  based on Yelp Rating and Google Rating and add Column to the DataFrame\n",
    "\n",
    "\n",
    "# Function that computes the weighted rating of each restaurant\n",
    "def aggregate_rating (x):\n",
    "    yelp_reviews = x['yelp_reviews']\n",
    "    yelp_rating = x['yelp_rating']\n",
    "    google_reviews = x['google_reviews']\n",
    "    google_rating = x['google_rating']\n",
    "    # Calculation\n",
    "    return ((yelp_rating*yelp_reviews)+(google_rating*google_reviews))/(yelp_reviews+google_reviews)\n",
    "\n",
    "def total_reviews (x):\n",
    "    yelp_reviews = x['yelp_reviews']\n",
    "    google_reviews = x['google_reviews']\n",
    "    return yelp_reviews+google_reviews\n",
    "\n",
    "master_df=pd.DataFrame(grand_master_list)\n",
    "master_df['agg_rating'] = master_df.apply(aggregate_rating, axis=1)\n",
    "master_df['total_reviews'] = master_df.apply(total_reviews, axis=1)\n",
    "master_df.agg_rating =master_df.agg_rating.round(2)\n",
    "\n",
    "master_df.to_csv('DataFiles/MasterList.csv')\n",
    "\n",
    "print('agg_rating and total_reviews fields created by combining Yelp and Google Ratings and Reviews.', flush=True)\n",
    "print('grand_master_list is now complete, has been saved as csv named \"MasterList.csv\".', flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:33:54.125028Z",
     "start_time": "2020-03-09T06:33:54.118582Z"
    }
   },
   "outputs": [],
   "source": [
    "#Postgres username, password, and database name\n",
    "ipaddress = 'localhost'\n",
    "port = '5432'\n",
    "username = username\n",
    "password = password \n",
    "dbname = 'Minneapolis_Restaurants'\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:51:46.709934Z",
     "start_time": "2020-03-09T06:51:46.165168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table \"grandmasterdata\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class GrandMasterData(Base):\n",
    "    __tablename__ = 'grandmasterdata'\n",
    "    index=Column(Integer,primary_key=True,autoincrement=True)\n",
    "    inspect_name=Column(String,nullable=False)\n",
    "    address=Column(String)\n",
    "    inspectionidnumber=Column(String)\n",
    "    dateofinspection=Column(String)\n",
    "    inspectionscore=Column(String)\n",
    "    inspectiontype=Column(String)\n",
    "    updated=Column(String)\n",
    "    yelp_id=Column(String,nullable=False)\n",
    "    yelp_name=Column(String)\n",
    "    yelp_url=Column(String)\n",
    "    yelp_price=Column(Integer)\n",
    "    latitude=Column(Float(20))\n",
    "    longitude=Column(Float(20))\n",
    "    yelp_phone=Column(String)\n",
    "    yelp_categories=Column(String)\n",
    "    yelp_transactions=Column(String)\n",
    "    yelp_rating=Column(Float(10))\n",
    "    yelp_reviews=Column(Integer)\n",
    "    google_name=Column(String)\n",
    "    google_id=Column(String)\n",
    "    google_rating=Column(Float(10))\n",
    "    google_reviews=Column(Integer)\n",
    "    google_price=Column(Integer)\n",
    "    agg_rating=Column(Float)\n",
    "    total_reviews=Column(Float)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "master_df.to_sql('grandmasterdata', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"grandmasterdata\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T06:34:08.362217Z",
     "start_time": "2020-03-09T06:33:55.156719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table \"inspectionsdetail\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".\n",
      "---------------\n",
      "DONE.  Don't forget to fix the SQL data types! Use the DataTypeChange script to fix your Minneapolis_Restaurants DB\n"
     ]
    }
   ],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class InspectionsDetail(Base):\n",
    "    __tablename__ = 'inspectionsdetail'\n",
    "    inspectionidnumber=Column(String,primary_key=True)\n",
    "    dateofinspection=Column(String)\n",
    "    businessname=Column(String)\n",
    "    fulladdress=Column(String)\n",
    "    inspectiontype=Column(String)\n",
    "    inspectionscore=Column(String)\n",
    "    inspectionresult=Column(String)\n",
    "    foodcodeitem=Column(String)\n",
    "    foodcodetext=Column(String)\n",
    "    inspectorcomments=Column(String)\n",
    "    violationpriority=Column(String)\n",
    "    violationstatus=Column(String)\n",
    "    violationpoints=Column(String)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "inspections_detail.to_sql('inspectionsdetail', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"inspectionsdetail\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------',flush=True)\n",
    "print(\"DONE.  Don't forget to fix the SQL data types! Use the DataTypeChange script to fix your Minneapolis_Restaurants DB\",flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
