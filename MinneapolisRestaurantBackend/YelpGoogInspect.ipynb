{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:55:31.327785Z",
     "start_time": "2020-02-15T17:55:30.383310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from config import api_key\n",
    "from config import google_key\n",
    "import time\n",
    "\n",
    "from config import password\n",
    "from config import username\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import PrimaryKeyConstraint\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime\n",
    "from sqlalchemy.schema import Sequence\n",
    "\n",
    "print(f'Dependencies imported...',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:55:55.727824Z",
     "start_time": "2020-02-15T17:55:33.113251Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download 1000 restaurants from Yelp API with Minneapolis as the search parameter.\n",
    "\n",
    "data = []\n",
    "\n",
    "headers = {'Authorization': 'Bearer %s' % api_key}\n",
    "\n",
    "url='https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "print('Downloading Yelp Data...',flush=True)\n",
    "\n",
    "for offset in range(0, 1000, 50):\n",
    "    \n",
    "    params = {\n",
    "        'limit':50, \n",
    "        'location':'Minneapolis, MN',\n",
    "\n",
    "        'categories':'restaurants',\n",
    "        'offset':offset\n",
    "        }  \n",
    "    \n",
    "    response=requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data += response.json()['businesses']\n",
    "    elif response.status_code == 400:\n",
    "        print('400 Bad Request')\n",
    "        break\n",
    "        \n",
    "print(f'Yelp data downloaded...  There are {len(data)} records...',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:55:55.747766Z",
     "start_time": "2020-02-15T17:55:55.730816Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "yelp_list=[]\n",
    "for places in data:\n",
    "    yelp_id=data[i]['id']\n",
    "    name=data[i]['name']\n",
    "    image=data[i]['image_url']\n",
    "    categories = []\n",
    "    for category in data[i]['categories']:\n",
    "        cat = category['title']\n",
    "        categories.append(cat)\n",
    "    url=data[i]['url']\n",
    "    transactions=data[i]['transactions']\n",
    "    city=data[i]['location']['city']\n",
    "#     price=data[i]['price']\n",
    "    phone=data[i]['display_phone']\n",
    "    address= data[i]['location']['display_address']\n",
    "    rating=data[i]['rating']\n",
    "    reviews=data[i]['review_count']\n",
    "    latitude=data[i]['coordinates']['latitude']\n",
    "    longitude=data[i]['coordinates']['longitude']\n",
    "    if data[i]['is_closed']==False and city==\"Minneapolis\":\n",
    "        business_dict={\"yelpid\":yelp_id,\"name\":name,\"image\":image,\"url\":url,\"latitude\":latitude,\"longitude\":longitude,\"phone\":phone,\"categories\":categories,\"transactions\":transactions,\"address\":' '.join(map(str, address)),\"rating\":rating,\"reviews\":reviews}\n",
    "        yelp_list.append(business_dict)\n",
    "    i+=1\n",
    "\n",
    "print('yelp_list with needed data has been built.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:55:57.805770Z",
     "start_time": "2020-02-15T17:55:57.782829Z"
    }
   },
   "outputs": [],
   "source": [
    "yelp_df=pd.DataFrame(yelp_list)\n",
    "yelp_df=yelp_df[['yelpid','name','image','url','latitude','longitude','address','phone','categories','transactions','rating','reviews']]\n",
    "yelp_df = yelp_df.drop_duplicates(subset=['name','address'])\n",
    "\n",
    "print('Yelp DataFrame now stored in memory as \"yelp_df\"',flush=True)\n",
    "print(f'Removed duplicates and restaurants outside of Minneapolis. Leaving {len(yelp_df)} restaurants.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T22:51:27.574515Z",
     "start_time": "2020-02-08T22:51:05.606841Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching Yelp data list to Google API...   This will take some time, as we match each record...',flush=True)\n",
    "\n",
    "url = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?'\n",
    "google_data=[]\n",
    "\n",
    "for index,row in yelp_df.iterrows():\n",
    "    \n",
    "    params = {\n",
    "        'key':google_key,\n",
    "        'input':row['name'],\n",
    "        'inputtype':'textquery',\n",
    "        'locationbias': 'point:' + str(row['latitude']) + \", \" + str(row['longitude']),\n",
    "        'radius': 10,\n",
    "        'fields':'place_id,name,formatted_address,geometry,rating,user_ratings_total,price_level,photos,icon'\n",
    "        }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if len(response.json()['candidates'])>0:\n",
    "        google_data.append(response.json()['candidates'][0])\n",
    "    else:\n",
    "        google_data.append(\"\")\n",
    "        \n",
    "   print(\"Restaurants Remaining: {:3}\".format(len(yelp_df)-index), end=\"\\r\",flush=True)\n",
    "\n",
    "print(f'Google match has been completed...  There are {len(google_data)} records',flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T22:51:34.524053Z",
     "start_time": "2020-02-08T22:51:34.516091Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "google_list=[]\n",
    "\n",
    "for places in google_data:\n",
    "    if places != \"\":\n",
    "        if \"place_id\" in places:\n",
    "            google_id = places['place_id']\n",
    "        if \"icon\"in places:\n",
    "            icon=places['icon']\n",
    "        photos=[]\n",
    "        if \"photos\" in places:\n",
    "            for photo in places['photos']:\n",
    "                item = photo['html_attributions']\n",
    "                photos.append(item)\n",
    "        if \"price_level\" in places:\n",
    "            price_level=places['price_level']\n",
    "        if \"name\" in places:\n",
    "            name = places['name']\n",
    "        if \"formatted_address\" in places:\n",
    "            address = places['formatted_address']\n",
    "        if \"rating\" in places:\n",
    "            rating  = places['rating']\n",
    "        if \"user_ratings_total\" in places:\n",
    "            reviews = places['user_ratings_total']\n",
    "        if \"geometry\" in places:\n",
    "            latitude = places['geometry']['location']['lat']\n",
    "            longitude = places['geometry']['location']['lng']\n",
    "        business_dict = {\"googleplacesid\":google_id,\"icon\":icon,\"photos\":photos,\"name\":name,\"latitude\":latitude,\"longitude\":longitude,\"address\":address,\"rating\":rating,\"reviews\":reviews,\"price\":price_level}\n",
    "    \n",
    "    else:\n",
    "        business_dict = {\"googleplacesid\":\"\",\"icon\":\"\",\"photos\":\"\",\"name\":\"\",\"latitude\":\"\",\"longitude\":\"\",\"address\":\"\", \"rating\":\"\",\"reviews\":\"\",\"price\":\"\"}\n",
    "    \n",
    "    google_list.append(business_dict)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "print('google_list with needed data has been built.',flush=True)google_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T22:51:40.880472Z",
     "start_time": "2020-02-08T22:51:40.860525Z"
    }
   },
   "outputs": [],
   "source": [
    "google_df=pd.DataFrame(google_list)\n",
    "google_df=google_df[google_df.name != \"\"]\n",
    "google_df = google_df.drop_duplicates(subset=['googleplacesid'])\n",
    "\n",
    "google_df=google_df[['googleplacesid','name','latitude','longitude','address','rating','reviews','price','icon','photos']]\n",
    "\n",
    "google_df.to_csv('DataFiles/googledata.csv')\n",
    "\n",
    "\n",
    "print('Google DataFrame now stored in memory as \"google_df\".',flush=True)\n",
    "print(f'Removed null entries.  {len(google_df)} restaurants remain.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-08T22:51:44.435133Z",
     "start_time": "2020-02-08T22:51:44.423156Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "compare_list=[]\n",
    "yelpgeo_list=[]\n",
    "\n",
    "for i in range(len(google_list)):\n",
    "\n",
    "    compare = {\"Yelp\":yelp_list[i]['name'],\"Google\":google_list[i]['name'],\"GoogleAddress\":google_list[i]['address'],\"Yelp Address\":yelp_list[i]['address']}\n",
    "    compare_list.append(compare)\n",
    "    i+=1\n",
    "\n",
    "compare_df = pd.DataFrame(compare_list)\n",
    "compare_df.to_csv('DataFiles/compare.csv')\n",
    "\n",
    "print('\"compare_df\" has been stored in memory and csv \"compare.csv\" has been saved in DataFiles folder to allow easy comparison between Yelp and Google data.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:32.215445Z",
     "start_time": "2020-02-15T17:56:10.899295Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching Yelp data list to Minneapolis Health Inspection API...   This will take some time, as we match each record...',flush=True)\n",
    "\n",
    "inspection_data=[]\n",
    "\n",
    "for index,row in yelp_df.iterrows():\n",
    "\n",
    "    biz = row['name']\n",
    "\n",
    "    biz_string = biz.split(' ',1)[0].upper()\n",
    "    biz_string = biz_string.replace(\"'\",\"\")\n",
    "    biz_string = biz_string.replace(\"&\",\"\")\n",
    "\n",
    "    minlat=row['latitude']-.0015\n",
    "    maxlat=row['latitude']+.0015\n",
    "    minlon=row['longitude']-.0015\n",
    "    maxlon=row['longitude']+.0015\n",
    "    \n",
    "    url = 'https://services.arcgis.com/afSMGVsC7QlRK1kZ/arcgis/rest/services/Food_Inspections/FeatureServer/0/query?'\n",
    "    params = f\"where=BusinessName%20like%20'%25{biz_string}%25'%20AND%20Latitude%20%3E%3D%20{minlat}%20AND%20Latitude%20%3C%3D%20{maxlat}%20AND%20Longitude%20%3E%3D%20{minlon}%20AND%20Longitude%20%3C%3D%20{maxlon}\"\n",
    "    outfields = \"&outFields=BusinessName,HealthFacilityIDNumber,FullAddress,InspectionType,DateOfInspection,InspectionIDNumber,InspectionScore,Latitude,Longitude,FoodCodeText,ViolationPoints,InspectionResult,FoodCodeItem,InspectorComments,ViolationStatus,ViolationPriority&returnGeometry=false&outSR=4326\"\n",
    "    json = '&f=json'\n",
    "\n",
    "    full_url = url+params+outfields+json\n",
    "\n",
    "    response = requests.get(full_url)\n",
    "    \n",
    "    if response !=\"\":\n",
    "        inspection_data += response.json()['features']\n",
    "        \n",
    "    print(\"Restaurants Remaining: {:3}\".format(len(yelp_df)-index), end=\"\\r\",flush=True)\n",
    "    \n",
    "print(f'Inspection data match has been completed...  There are {len(inspection_data)} records',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:35.541651Z",
     "start_time": "2020-02-15T17:59:35.344177Z"
    }
   },
   "outputs": [],
   "source": [
    "# inspection_data = inspection_data.sort(key=operator.itemgetter(attributes[DateOfInspection]))\n",
    "# inspection_data=inspection_data.attributes\n",
    "inspection_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:41.643675Z",
     "start_time": "2020-02-15T17:59:41.568868Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_data_list = []\n",
    "\n",
    "for records in inspection_data:\n",
    "    item = records['attributes']\n",
    "    item['DateOfInspection']=time.strftime('%Y/%m/%d',time.gmtime(records['attributes']['DateOfInspection']/1000))\n",
    "    inspection_data_list.append(item)\n",
    "    \n",
    "print('inspection_data_list with needed data has been built.',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:46.011828Z",
     "start_time": "2020-02-15T17:59:45.801373Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:51.992206Z",
     "start_time": "2020-02-15T17:59:51.838618Z"
    }
   },
   "outputs": [],
   "source": [
    "inspections_df_base = pd.DataFrame(inspection_data_list)\n",
    "\n",
    "inspections_df_1 = inspections_df_base[['InspectionIDNumber','DateOfInspection','BusinessName','FullAddress','InspectionType','InspectionScore','Latitude','Longitude']]\n",
    "inspections_df_1 = inspections_df_1.drop_duplicates(subset='InspectionIDNumber', keep='first')\n",
    "inspections_df_1 = inspections_df_1.sort_values(by=['BusinessName','DateOfInspection'])\n",
    "inspections_df_1 = inspections_df_1.rename(columns={'BusinessName':'businessname','FullAddress':'fulladdress','Latitude':'latitude','Longitude':'longitude','InspectionIDNumber':'inspectionidnumber','DateOfInspection':'dateofinspection','InspectionScore':'inspectionscore','InspectionType':'inspectiontype'})\n",
    "\n",
    "inspections_df_2 = inspections_df_base[['DateOfInspection','InspectionIDNumber','BusinessName','FullAddress','InspectionType','InspectionScore','InspectionResult','FoodCodeItem','FoodCodeText','InspectorComments','ViolationPriority','ViolationStatus','ViolationPoints']]\n",
    "inspections_df_2 = inspections_df_2.sort_values(by=['BusinessName','DateOfInspection'])\n",
    "inspections_df_2 = inspections_df_2.rename(columns={'InspectionIDNumber':'inspectionidnumber','DateOfInspection':'dateofinspection','BusinessName':'businessname','FullAddress':'fulladdress','InspectionType':'inspectiontype','InspectionScore':'inspectionscore','InspectionResult':'inspectionresult','FoodCodeItem':'foodcodeitem','FoodCodeText':'foodcodetext','InspectorComments':'inspectorcomments','ViolationPriority':'violationpriority','ViolationStatus':'violationstatus','ViolationPoints':'violationpoints'})\n",
    "\n",
    "inspections_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T17:59:57.982354Z",
     "start_time": "2020-02-15T17:59:57.949409Z"
    }
   },
   "outputs": [],
   "source": [
    "inspections_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:00:08.291399Z",
     "start_time": "2020-02-15T18:00:08.084950Z"
    }
   },
   "outputs": [],
   "source": [
    "inspect_by_biz=inspections_df_1.groupby(['businessname','fulladdress','latitude','longitude'],sort=False,as_index=False).aggregate(lambda x: list(x))\n",
    "\n",
    "print('Inspections DataFrame now stored in memory as \"inspect_by_biz\" and csv \"InspectionsData.csv\" has been saved in DataFiles folder.')\n",
    "print(f'There are {len(inspections_df_1)} inspections for {len(inspect_by_biz)} facilities.')\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:00:21.811316Z",
     "start_time": "2020-02-15T18:00:20.305345Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_detail=inspections_df_2\n",
    "\n",
    "print('Inspection Detail DataFrame now stored in memory as \"inspection_detail\"',flush=True)\n",
    "\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:00:24.349025Z",
     "start_time": "2020-02-15T18:00:24.259268Z"
    }
   },
   "outputs": [],
   "source": [
    "inspection_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:00:51.569636Z",
     "start_time": "2020-02-15T18:00:51.564647Z"
    }
   },
   "outputs": [],
   "source": [
    "#Postgres username, password, and database name\n",
    "ipaddress = 'localhost'\n",
    "port = '5432'\n",
    "username = username\n",
    "password = password \n",
    "dbname = 'Minneapolis_Restaurants'\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:44:41.857000Z",
     "start_time": "2020-02-06T14:44:41.496962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class YelpData(Base):\n",
    "    __tablename__ = 'yelpdata'\n",
    "    index=Column(Integer,primary_key=True,autoincrement=True)\n",
    "    yelpid=Column(String,nullable=False)\n",
    "    name=Column(String)\n",
    "    image=Column(String)\n",
    "    url=Column(String)\n",
    "    latitude=Column(Float(20))\n",
    "    longitude=Column(Float(20))\n",
    "    address=Column(String)\n",
    "    phone=Column(String)\n",
    "    categories=Column(String)\n",
    "    transactions=Column(String)\n",
    "    rating=Column(Float(10))\n",
    "    reviews=Column(Integer)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "yelp_df.to_sql('yelpdata', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"yelpdata\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T14:41:36.554044Z",
     "start_time": "2020-02-06T14:32:27.065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class GoogleData(Base):\n",
    "    __tablename__ = 'googledata'\n",
    "    googleplacesid=Column(String,primary_key=True, nullable=False)\n",
    "    name=Column(String)\n",
    "    latitude=Column(Float(20))\n",
    "    longitude=Column(Float(20))\n",
    "    address=Column(String)\n",
    "    rating=Column(Float(10))\n",
    "    reviews=Column(Integer) \n",
    "    price=Column(Integer)\n",
    "    icon=Column(String)\n",
    "    photos=Column(String)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "google_df.to_sql('googledata', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"googledata\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:01:09.943522Z",
     "start_time": "2020-02-15T18:01:09.738090Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class InspectionsData(Base):\n",
    "    __tablename__ = 'inspectionsdata'\n",
    "    index=Column(Integer,primary_key=True,autoincrement=True)\n",
    "    businessname=Column(String,nullable=False)\n",
    "    fulladdress=Column(String)\n",
    "    healthfacilityidnumber=Column(String)\n",
    "    latitude=Column(Float(20))\n",
    "    longitude=Column(Float(20))\n",
    "    inspectionidnumber=Column(String)\n",
    "    dateofinspection=Column(String)\n",
    "    inspectionscore=Column(String)\n",
    "    inspectiontype=Column(String)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "inspect_by_biz.to_sql('inspectionsdata', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"inspectionsdata\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-15T18:01:13.482139Z",
     "start_time": "2020-02-15T18:01:12.417800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "\n",
    "class InspectionsData(Base):\n",
    "    __tablename__ = 'inspectionsdata'\n",
    "    inspectionidnumber=Column(String,primary_key=True)\n",
    "    dateofinspection=Column(String)\n",
    "    businessname=Column(String)\n",
    "    fulladdress=Column(String)\n",
    "    inspectiontype=Column(String)\n",
    "    inspectionscore=Column(String)\n",
    "    inspectionresult=Column(String)\n",
    "    foodcodeitem=Column(String)\n",
    "    foodcodetext=Column(String)\n",
    "    inspectorcomments=Column(String)\n",
    "    violationpriority=Column(String)\n",
    "    violationstatus=Column(String)\n",
    "    violationpoints=Column(String)\n",
    "                   \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "inspection_detail.to_sql('inspectionsdetail', engine, if_exists='replace', index=True)\n",
    "\n",
    "print(f'Table \"inspectionsdetail\" uploaded to postgreSQL database \"Minneapolis_Restaurants\".',flush=True)\n",
    "print('---------------',flush=True)\n",
    "print(\"DONE.  Don't forget to fix the SQL data types! Use the DataTypeChange script to fix your Minneapolis_Restaurants DB\",flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
